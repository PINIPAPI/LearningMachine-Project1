trainCapAve <- training$capitalAve
trainCapAveS <- (trainCapAve  - mean(trainCapAve))/sd(trainCapAve)
mean(trainCapAveS)
sd(trainCapAveS)
testCapAve <- testing$capitalAve
testCapAveS <- (testCapAve  - mean(trainCapAve))/sd(trainCapAve)
mean(testCapAveS)
sd(testCapAveS)
preObj <- preProcess(training[,-58],method=c("center","scale"))
trainCapAveS <- predict(preObj,training[,-58])$capitalAve
mean(trainCapAveS)
sd(trainCapAveS)
testCapAveS <- predict(preObj,testing[,-58])$capitalAve
mean(testCapAveS)
sd(testCapAveS)
set.seed(32343)
modelFit <- train(type ~.,data=training,
preProcess=c("center","scale"),method="glm")
modelFit
preObj <- preProcess(training[,-58],method=c("BoxCox"))
trainCapAveS <- predict(preObj,training[,-58])$capitalAve
par(mfrow=c(1,2)); hist(trainCapAveS); qqnorm(trainCapAveS)
set.seed(13343)
# Make some values NA
training$capAve <- training$capitalAve
selectNA <- rbinom(dim(training)[1],size=1,prob=0.05)==1
training$capAve[selectNA] <- NA
# Impute and standardize
preObj <- preProcess(training[,-58],method="knnImpute")
capAve <- predict(preObj,training[,-58])$capAve
# Standardize true values
capAveTruth <- training$capitalAve
capAveTruth <- (capAveTruth-mean(capAveTruth))/sd(capAveTruth)
quantile(capAve - capAveTruth)
quantile((capAve - capAveTruth)[selectNA])
quantile((capAve - capAveTruth)[!selectNA])
set.seed(13343)
# Make some values NA
training$capAve <- training$capitalAve
selectNA <- rbinom(dim(training)[1],size=1,prob=0.05)==1
training$capAve[selectNA] <- NA
# Impute and standardize
preObj <- preProcess(training[,-58],method="knnImpute")
capAve <- predict(preObj,training[,-58])$capAve
# Standardize true values
capAveTruth <- training$capitalAve
capAveTruth <- (capAveTruth-mean(capAveTruth))/sd(capAveTruth)
install.packages("RANN")
library(RANN)
set.seed(13343)
# Make some values NA
training$capAve <- training$capitalAve
selectNA <- rbinom(dim(training)[1],size=1,prob=0.05)==1
training$capAve[selectNA] <- NA
# Impute and standardize
preObj <- preProcess(training[,-58],method="knnImpute")
capAve <- predict(preObj,training[,-58])$capAve
# Standardize true values
capAveTruth <- training$capitalAve
capAveTruth <- (capAveTruth-mean(capAveTruth))/sd(capAveTruth)
quantile(capAve - capAveTruth)
quantile((capAve - capAveTruth)[selectNA])
quantile((capAve - capAveTruth)[!selectNA])
library(kernlab);data(spam)
spam$capitalAveSq <- spam$capitalAve^2
View(spam)
library(kernlab);data(spam)
spam$capitalAveSq <- spam$capitalAve^2
library(ISLR); library(caret); data(Wage);
inTrain <- createDataPartition(y=Wage$wage,
p=0.7, list=FALSE)
training <- Wage[inTrain,]; testing <- Wage[-inTrain,]
table(training$jobclass)
dummies <- dummyVars(wage ~ jobclass,data=training)
head(predict(dummies,newdata=training))
nsv <- nearZeroVar(training,saveMetrics=TRUE)
nsv
library(splines)
bsBasis <- bs(training$age,df=3)
bsBasis
lm1 <- lm(wage ~ bsBasis,data=training)
plot(training$age,training$wage,pch=19,cex=0.5)
points(training$age,predict(lm1,newdata=training),col="red",pch=19,cex=0.5)
predict(bsBasis,age=testing$age)
library(caret); library(kernlab); data(spam)
inTrain <- createDataPartition(y=spam$type,
p=0.75, list=FALSE)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
M <- abs(cor(training[,-58]))
diag(M) <- 0
which(M > 0.8,arr.ind=T)
M <- abs(cor(training[,-58]))
View(M)
diag(M) <- 0
which(M > 0.8,arr.ind=T)
View(M)
names(spam)[c(34,32)]
plot(spam[,34],spam[,32])
X <- 0.71*training$num415 + 0.71*training$num857
Y <- 0.71*training$num415 - 0.71*training$num857
plot(X,Y)
smallSpam <- spam[,c(34,32)]
prComp <- prcomp(smallSpam)
plot(prComp$x[,1],prComp$x[,2])
prComp$rotation
typeColor <- ((spam$type=="spam")*1 + 1)
prComp <- prcomp(log10(spam[,-58]+1))
plot(prComp$x[,1],prComp$x[,2],col=typeColor,xlab="PC1",ylab="PC2")
preProc <- preProcess(log10(spam[,-58]+1),method="pca",pcaComp=2)
spamPC <- predict(preProc,log10(spam[,-58]+1))
plot(spamPC[,1],spamPC[,2],col=typeColor)
preProc <- preProcess(log10(training[,-58]+1),method="pca",pcaComp=2)
trainPC <- predict(preProc,log10(training[,-58]+1))
modelFit <- train(training$type ~ .,method="glm",data=trainPC)
testPC <- predict(preProc,log10(testing[,-58]+1))
confusionMatrix(testing$type,predict(modelFit,testPC))
modelFit <- train(training$type ~ .,method="glm",preProcess="pca",data=training)
confusionMatrix(testing$type,predict(modelFit,testing))
library(caret);data(faithful); set.seed(333)
inTrain <- createDataPartition(y=faithful$waiting,
p=0.5, list=FALSE)
trainFaith <- faithful[inTrain,]; testFaith <- faithful[-inTrain,]
head(trainFaith)
plot(trainFaith$waiting,trainFaith$eruptions,pch=19,col="blue",xlab="Waiting",ylab="Duration")
lm1 <- lm(eruptions ~ waiting,data=trainFaith)
summary(lm1)
plot(trainFaith$waiting,trainFaith$eruptions,pch=19,col="blue",xlab="Waiting",ylab="Duration")
lines(trainFaith$waiting,lm1$fitted,lwd=3)
coef(lm1)[1] + coef(lm1)[2]*80
newdata <- data.frame(waiting=80)
predict(lm1,newdata)
par(mfrow=c(1,2))
plot(trainFaith$waiting,trainFaith$eruptions,pch=19,col="blue",xlab="Waiting",ylab="Duration")
lines(trainFaith$waiting,predict(lm1),lwd=3)
plot(testFaith$waiting,testFaith$eruptions,pch=19,col="blue",xlab="Waiting",ylab="Duration")
lines(testFaith$waiting,predict(lm1,newdata=testFaith),lwd=3)
# Calculate RMSE on training
sqrt(sum((lm1$fitted-trainFaith$eruptions)^2))
# Calculate RMSE on test
sqrt(sum((predict(lm1,newdata=testFaith)-testFaith$eruptions)^2))
pred1 <- predict(lm1,newdata=testFaith,interval="prediction")
ord <- order(testFaith$waiting)
plot(testFaith$waiting,testFaith$eruptions,pch=19,col="blue")
matlines(testFaith$waiting[ord],pred1[ord,],type="l",,col=c(1,2,2),lty = c(1,1,1), lwd=3)
modFit <- train(eruptions ~ waiting,data=trainFaith,method="lm")
summary(modFit$finalModel)
library(ISLR); library(ggplot2); library(caret);
data(Wage); Wage <- subset(Wage,select=-c(logwage))
summary(Wage)
inTrain <- createDataPartition(y=Wage$wage,
p=0.7, list=FALSE)
training <- Wage[inTrain,]; testing <- Wage[-inTrain,]
dim(training); dim(testing)
featurePlot(x=training[,c("age","education","jobclass")],
y = training$wage,
plot="pairs")
qplot(age,wage,data=training)
qplot(age,wage,colour=jobclass,data=training)
qplot(age,wage,colour=education,data=training)
modFit<- train(wage ~ age + jobclass + education,
method = "lm",data=training)
finMod <- modFit$finalModel
print(modFit)
plot(finMod,1,pch=19,cex=0.5,col="#00000010")
plot(finMod,1,pch=19,cex=0.5,col="#00000010")
qplot(finMod$fitted,finMod$residuals,colour=race,data=training)
plot(finMod$residuals,pch=19)
pred <- predict(modFit, testing)
qplot(wage,pred,colour=year,data=testing)
modFitAll<- train(wage ~ .,data=training,method="lm")
pred <- predict(modFitAll, testing)
qplot(wage,pred,data=testing)
install.packages("RCurl")
library(knitr); library(caret); library(RCurl)
library(ggplot2); library(caret);library(RCurl)
# Download data.
dir_data_training <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
file_data_training <- "pml-training.csv"
download.file(url=dir_data_training, destfile=file_data_training, method="curl")
dir_data_training <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
file_data_training <- "pml-training.csv"
download.file(url=dir_data_training, destfile=file_data_training, method="curl")
library(ggplot2); library(caret);library(RCurl)
# Download data.
setInternet2(use=T)
dir_data_training <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
file_data_training <- "pml-training.csv"
download.file(url=dir_data_training, destfile=file_data_training, method="curl")
dir_data_training <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
file_data_training <- "pml-training.csv"
download.file(url=dir_data_training, destfile=file_data_training)
dir_data_testing <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
file_data_testing <- "pml-testing.csv"
download.file(url=dir_data_testing, destfile=file_data_testing)
training <- read.csv(file_data_training, na.strings=c("NA",""), header=TRUE)
colnames_train <- colnames(training)
testing <- read.csv(file_data_testing, na.strings=c("NA",""), header=TRUE)
colnames_test <- colnames(testing)
summary(training)
rm(list=ls())
# Download data.
dir_data_training <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
file_data_training <- "pml-training.csv"
download.file(url=dir_data_training, destfile=file_data_training)
dir_data_testing <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
file_data_testing <- "pml-testing.csv"
download.file(url=dir_data_testing, destfile=file_data_testing)
# Import the data treating empty values as NA.
training <- read.csv(file_data_training, na.strings=c("NA",""), header=TRUE)
colnames_train <- colnames(training)
testing <- read.csv(file_data_testing, na.strings=c("NA",""), header=TRUE)
colnames_test <- colnames(testing)
View(training)
summary(training)
summary(testing)
dim(training)
dim(testing)
library(ISLR); library(ggplot2); library(caret);
data(Wage); Wage <- subset(Wage,select=-c(logwage))
summary(Wage)
View(Wage)
View(training)
View(testing)
colnames_test
summary(training)
dim(training)
dim(testing)
SubTrain <- createDataPartition(y=training$classe,
p=0.6, list=FALSE)
Subtraining <- training[SubTrain,]; Subtesting <- trining[-SubTrain,]
dim(Subtraining); dim(Subtesting)
SubTrain <- createDataPartition(y=training$classe,
p=0.6, list=FALSE)
Subtraining <- training[SubTrain,]; Subtesting <- training[-SubTrain,]
dim(Subtraining); dim(Subtesting)
featurePlot(x=Subtraining[,c("gyros_forearm_z","accel_forearm_z","magnet_forearm_z")],
y = Subtraining$classe,
plot="pairs")
featurePlot(x=Subtraining[,c("gyros_forearm_z","accel_forearm_z","magnet_forearm_z","classe")],
y = Subtraining$classe,
plot="pairs")
qplot(magnet_forearm_z,classe,data=Subtraining)
qplot(magnet_forearm_z,classe,colour=accel_forearm_z,data=Subtraining)
install.packages("rattle")
par(mar=c(0,0,0,0)); set.seed(1234); x = rep(1:4,each=4); y = rep(1:4,4)
plot(x,y,xaxt="n",yaxt="n",cex=3,col=c(rep("blue",15),rep("red",1)),pch=19)
par(mar=c(0,0,0,0));
plot(x,y,xaxt="n",yaxt="n",cex=3,col=c(rep("blue",8),rep("red",8)),pch=19)
data(iris); library(ggplot2)
names(iris)
table(iris$Species)
inTrain <- createDataPartition(y=iris$Species,
p=0.7, list=FALSE)
library(knitr); library(caret); library(rattle)
inTrain <- createDataPartition(y=iris$Species,
p=0.7, list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
dim(training); dim(testing)
View(testing)
qplot(Petal.Width,Sepal.Width,colour=Species,data=training)
library(caret)
modFit <- train(Species ~ .,method="rpart",data=training)
print(modFit$finalModel)
```{r, dependson="createTree", fig.height=4.5, fig.width=4.5}
plot(modFit$finalModel, uniform=TRUE,
main="Classification Tree")
text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
```{r, dependson="createTree", fig.height=4.5, fig.width=4.5}
library(rattle)
fancyRpartPlot(modFit$finalModel)
install.packages("rpart.plot")
fancyRpartPlot(modFit$finalModel)
predict(modFit,newdata=testing)
```{r fig.height=4,fig.width=4,cache=TRUE}
modFit <- train(classe~ .,data=Subtraining,method="rf",prox=TRUE)
modFit <- train(classe~ .,data=Subtraining,method="rf",prox=TRUE)
modFit <- train(classe~ .,data=training,method="rf",prox=TRUE)
modFit <- train(classe~ .,data=Subtraining,method="rf",prox=TRUE)
modFit <- train(classe~ .,data=training,method="rf",prox=TRUE)
data(iris); library(ggplot2)
inTrain <- createDataPartition(y=iris$Species,
p=0.7, list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
```
---
## Random forests
```{r forestIris, dependson="irisData",fig.height=4,fig.width=4,cache=TRUE}
library(caret)
modFit <- train(Species~ .,data=training,method="rf",prox=TRUE)
modFit <- train(Species~ .,data=training,method="rf",prox=TRUE)
modFit
modFit <- train(classe~ .,data=training,method="rf",prox=TRUE)
SubTrain <- createDataPartition(y=training$classe,p=0.6, list=FALSE)
library(ggplot2); library(caret);library(RCurl)
# Download data.
dir_data_training <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
file_data_training <- "pml-training.csv"
download.file(url=dir_data_training, destfile=file_data_training)
dir_data_testing <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
file_data_testing <- "pml-testing.csv"
download.file(url=dir_data_testing, destfile=file_data_testing)
# Import the data treating empty values as NA.
training <- read.csv(file_data_training, na.strings=c("NA",""), header=TRUE)
colnames_train <- colnames(training)
testing <- read.csv(file_data_testing, na.strings=c("NA",""), header=TRUE)
colnames_test <- colnames(testing)
dim(training)
dim(testing)
SubTrain <- createDataPartition(y=training$classe,p=0.6, list=FALSE)
Subtraining <- training[SubTrain,]; Subtesting <- training[-SubTrain,]
dim(Subtraining); dim(Subtesting)
modFit <- train(classe~ .,data=training,method="rf",prox=TRUE)
modFit <- train(classe~ .,data=Subtraining,method="rf",prox=TRUE)
na_test = sapply(Subtraining, function(x) {sum(is.na(x))})
table(na_test)
bad_columns = names(na_test[na_test==13460])
training = training[, !names(training) %in% bad_columns]
SubTrain <- createDataPartition(y=training$classe,p=0.6, list=FALSE)
Subtraining <- training[SubTrain,]; Subtesting <- training[-SubTrain,]
dim(Subtraining); dim(Subtesting)
modFit <- train(classe~ .,data=Subtraining,method="rf",prox=TRUE)
str(training)
na_test = sapply(Subtraining, function(x) {sum(is.na(x))})
table(na_test)
bad_columns = names(na_test[na_test==13460])
training = training[, !names(training) %in% bad_columns]
str(training)
modFit <- train(classe~ .,data=Subtraining,method="rf",prox=TRUE)
training1 <- na.omit(training)
training <- read.csv(file_data_training, na.strings=c("NA",""), header=TRUE)
colnames_train <- colnames(training)
testing <- read.csv(file_data_testing, na.strings=c("NA",""), header=TRUE)
colnames_test <- colnames(testing)
dim(training)
dim(testing)
training1 <- na.omit(training)
View(training1)
View(training)
training1 <- factor(training)
rm(trining1)
rm(training1)
training1 <- factor(training)
na_test = sapply(training, function(x) {sum(is.na(x))})
table(na_test)
bad_columns = names(na_test[na_test==13460])
bad_columns = names(na_test)
training1 = training[, !names(training) %in% bad_columns]
View(training1)
View(training)
bad_columns = names(na_test)
na_test = sapply(training, function(x) {sum(is.na(x))})
table(na_test)
bad_columns = names(na_test[na_test==19216])
training1 = training[, !names(training) %in% bad_columns]
na_test = sapply(training, function(x) {sum(is.na(x))})
table(na_test)
bad_columns = names(na_test[na_test==19216])
training1 = training[, !names(training) %in% bad_columns]
SubTrain <- createDataPartition(y=training1$classe,p=0.6, list=FALSE)
Subtraining <- training1[SubTrain,]; Subtesting <- training1[-SubTrain,]
dim(Subtraining); dim(Subtesting)
modFit <- train(classe~ .,data=Subtraining,method="rf",prox=TRUE)
modFit
getTree(modFit$finalModel,k=2)
View(Subtraining)
View(training)
View(Subtraining)
str(Subtraining)
colnames(Subtraining)
data(iris); library(ggplot2)
show(iris)
View(iris)
colnames(Subtraining)
irisP <- classCenter(Subtraining[,c(55,56)], Subtraining$Classe, modFit$finalModel$prox)
irisP <- as.data.frame(irisP); irisP$classe <- rownames(irisP)
p <- qplot(accel_forearm_y, accel_forearm_z, col=classe,data=Subtraining)
p + geom_point(aes(x=accel_forearm_y,y=accel_forearm_z,col=classe),size=5,shape=4,data=Subtraining)
pred <- predict(modFit,Subtesting); Subtesting$predRight <- pred==Subtesting$classe
table(pred,Subtesting$classe)
rm(list = ls())
training <- read.csv(file_data_training, na.strings=c("NA",""), header=TRUE)
setwd("D:/cpinilla/personal/DataScientific/LearningMachine/Project/LearningMachine-Project1")
training <- read.csv(file_data_training, na.strings=c("NA",""), header=TRUE)
library(ggplot2); library(caret);library(RCurl)
library(knitr); library(caret); library(randomForest)
training <- read.csv(file_data_training, na.strings=c("NA",""), header=TRUE)
file_data_training <- "pml-training.csv"
file_data_testing <- "pml-testing.csv"
training <- read.csv(file_data_training, na.strings=c("NA",""), header=TRUE)
colnames_train <- colnames(training)
testing <- read.csv(file_data_testing, na.strings=c("NA",""), header=TRUE)
colnames_test <- colnames(testing)
dim(training)
dim(testing)
na_test = sapply(training, function(x) {sum(is.na(x))})
table(na_test)
bad_columns = names(na_test[na_test==19216])
training1 = training[, !names(training) %in% bad_columns]
dim(training)
na_test = sapply(testing, function(x) {sum(is.na(x))})
table(na_test)
bad_columns = names(na_test[na_test==20])
testing = testing[, !names(testing) %in% bad_columns]
dim(testin)
dim(testing)
modFit <- train(classe~ .,data=Subtraining,method="rf")
modFit <- train(classe~ .,data=training,method="rf")
bad_columns = names(na_test[na_test==19216])
training = training[, !names(training) %in% bad_columns]
dim(training)
modFit <- train(classe~ .,data=training,method="rf")
na_test = sapply(training, function(x) {sum(is.na(x))})
table(na_test)
bad_columns = names(na_test[na_test==19216])
training = training[, !names(training) %in% bad_columns]
dim(training)
modFit <- train(classe~ .,data=training,method="rf")
modFit
pred <- predict(modFit,testing);
pred
View(testing)
pred2 <- predict(modFit,training);
pred2
answers <- predict(modFit,testing);
answers
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(answers)
answers <- predict(modFit,testing);
answers
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
View(segmentationOriginal)
training1 <- segmentationoriginal$Case == Train
training1 <- segmentationOriginal$Case == Train
training1 <- segmentationOriginal$Case == "Train"
View(training)
segmentationOriginal.df <- segmentationOriginal
training1 <- subset(segmentationOriginal.df,segmentationOriginal$Case == "Train")
View(training1)
test1 <- subset(segmentationOriginal.df,segmentationOriginal$Case == "Test")
set.seed 125
set.seed(125)
modfit <- train(class ~.,data = training1, method ="rpart")
modfit <- train(Class ~.,data = training1, method ="rpart")
modfit$finalModel
library(pgmm)
data(olive)
olive = olive[,-1]
install.packages("pgmm")
install.packages(c("boot", "chron", "class", "cluster", "codetools", "data.table", "digest", "dplyr", "evaluate", "foreign", "formatR", "highr", "Hmisc", "httpuv", "httr", "jsonlite", "KernSmooth", "lattice", "manipulate", "maps", "MASS", "mgcv", "mime", "nlme", "nnet", "quantmod", "R6", "Rcpp", "RcppEigen", "rmarkdown", "rpart", "scales", "spatial", "stringi", "stringr", "survival", "swirl", "testthat", "tidyr", "TTR", "UsingR"))
install.packages(c("boot", "chron", "class", "cluster", "codetools",
))
install.packages(c("boot", "chron", "class", "cluster", "codetools"))
install.packages(c("boot", "chron", "class", "cluster", "codetools"))
library(pgmm)
data(olive)
olive = olive[,-1]
View(olive)
modelFit <- train(Area ~.,data=olive,method="rpart")
modelFit <- train(Area ~.,data=olive,method="rpart2")
library(caret)
modelFit <- train(Area ~.,data=olive,method="rpart")
newdata = as.data.frame(t(colMeans(olive)))
View(newdata)
predict(modelFit,newdata=newdata)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
modelFit <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, data = trainSA, method = "glm", family = "binomial")
model <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, data = trainSA, method = "glm", family = "binomial")
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(testSA$chd, predict(model, newdata = testSA))
missClass(trainSA$chd, predict(model, newdata = trainSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
set.seed(33833)
a <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
b <- varImp(a)
order(b)
library*(randomForest)
library(randomForest)
a <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
b <- varImp(a)
order(b)
