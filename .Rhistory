remove.packages("plyr")
remove.packages("Dplyr")
remove.packages("dplyr")
install.packages("plyr")
install.packages("plyr")
library(dplyr)
install.packages("dplyr")
library(swirl)
swirl()
pt(2, df=15, lower.tail=FALSE)
pnorm(2)
pnorm(2,lower.tail= FALSE)
mybin(0,8)
12
mybin
pbinom(6,size=8,prob=.5, lower.tail=FALSE)
library(swirl)
swirl()
12
pbinom(7,size=8,prob=.5,lower.tail=TRUE)
12
ppois(9,5,lower.tail=FALSE)
2
0.8
15
qt(0.95,15)
dim(fs)
t.test(fs$sheight,fs$fheight,paired=TRUE)
11.7885 * sd(fs$sheight-fs$fheight)/sqrt(1078)
mybin
8
myplot(34)
myplot(33.3)
myplot(30)
myplot(28)
z <- qnorm(0.95)
pnorm(30+z,mean=30,lower.tail=FALSE)
pnorm(30+z,mean=32,lower.tail=FALSE)
pnorm(30+z,mean=32,sd=1,lower.tail=FALSE)
pnorm(30+z,mean=32,sd=2,lower.tail=FALSE)
pnorm(30+z*2,mean=32,sd=2,lower.tail=FALSE)
power.t.test(n=16,delta=2/4,sd=1,type="one.sample",alt = "one.sided")$power
power.t.test(n=16,delta=2,sd=4,type="one.sample",alt = "one.sided")$power
power.t.test(n=16,delta=100,sd=200,type="one.sample",alt = "one.sided")$power
power.t.test(power=0.8,delta=2/4,sd=1,type="one.sample",alt = "one.sided")$n
power.t.test(power=0.8,delta=2,sd=4,type="one.sample",alt = "one.sided")$n
power.t.test(power=0.8,delta=100,sd=200,type="one.sample",alt = "one.sided")$n
power.t.test(power=0.8,n=26,sd=1,type="one.sample",alt = "one.sided")$delta
power.t.test(power=0.8,n=27,sd=1,type="one.sample",alt = "one.sided")$delta
library(swirl)
swirl()
pvalues
head(pValues)
sum(pValues)
sum(pValues < 0.05)
sum(p.adjust)
12
sum(p.adjust(pValues,method="bonferroni") < 0.05)
sum(p.adjust(pValues,method="BH") < 0.05)
tail(trueStatus)
table(pvalies2<.05,trueStatus)
12
table(pValues2 < 0.05, trueStatus)
2.4
24/500
table(p.adjust(method="bonferroni"))
12
table(p.adjust(pValues2,method="bonferroni") < 0.05, trueStatus)
table(p.adjust(pValues2,method="BH") < 0.05, trueStatus)
3.5
R.Version.string
R.Version.string()
R.version.string
library(swirl)
swirl()
install_from_swirl("Regression Models")
library(swirl)
swirl()
plot(jitter(child,4) ~ parent,galton)
regrline <- lm(child ~ parent, galton)
abline(regrline, lwd=3, col='red')
summary(regrline)
12
boxplot(pm25 ~ region, data = pollution, col = "red")
par(mfrow=c(2,1),mar=c(4,4,2,1))
12
east <- subset(pollution,region=="east")
head(east)
hist(east$pm25,col="green")
12
hist(subset(pollution,region=="west")$pm25, col = "green")
12
with(pollution, plot(latitude, pm25))
12
abline(h = 12, lwd = 2, lty = 2)
80
plot(pollution$latitude, ppm, col = pollution$region)
12
abline(h = 12, lwd = 2, lty = 2)
12
par(mfrow = c(1, 2), mar = c(5, 4, 2, 1))
12
west <- subset(pollution,region=="west")
12
plot(west$latitude, west$pm25, main = "West")
12
plot(east$latitude, east$pm25, main = "East")
lm(child ~ parent, galton)
fit <- lm(child ~ parent, galton)
summary(fit)
fit$residuals
mean(fit$residuals)
library(swirl)
swirl()
cov(fit$residuals, galton$parent)
12
ols.ic <- fit$coef[1]
ols.slope <- fit$coef[2]
12
lhs-rhs
all.equal(lhs-rhs)
12
all.equal(lhs,rhs)
VarChild <- var(galton$children)
12
VarChild <- var(galton$child)
varChild <- var(galton$child)
VarRes <- var(fit$residuals)
varRes <- var(fit$residuals)
varEst <-
34
varEst <- var(est(ols.slope, ols.ic))
all.equal(varChild,sum(varRes,varEst))
all.equal(varChild,varRes+varEst)
efit <- lm(accel ~mag+dist, attenu)
mean(efit$residuals)
cov(efit$residuals, attenu$mag)
cov(efit$residuals, attenu$dist)
swirl()
cor(gpa_nor,gch_nor)
l_nor <- lm(parent,child,galton)
12
l_nor <- lm(gch_nor ~ gpa_nor)
library(swirl)
swirl()
cor(gpa_nor,gch_nor)
l_nor <- lm(galton$child ~ galton$parent, galton)
l_nor <- lm(gch_nor ~ gpa_nor)
y <- galton$child
x <- galton$parent
freqData <- as.data.frame(table(galton$child, galton$parent))
View(freqData)
View(freqData)
names(freqData) <- c("child", "parent", "freq")
plot(as.numeric(as.vector(freqData$parent)),
as.numeric(as.vector(freqData$child)),
pch = 21, col = "black", bg = "lightblue",
cex = .07 * freqData$freq, xlab = "parent", ylab = "child")
#original regression line, children as outcome, parents as predictor
abline(mean(y) - mean(x) * cor(y, x) * sd(y) / sd(x), #intercept
sd(y) / sd(x) * cor(y, x),  #slope
lwd = 3, col = "red")
#new regression line, parents as outcome, children as predictor
abline(mean(y) - mean(x) * sd(y) / sd(x) / cor(y, x), #intercept
sd(y) / cor(y, x) / sd(x), #slope
lwd = 3, col = "blue")
#assume correlation is 1 so slope is ratio of std deviations
abline(mean(y) - mean(x) * sd(y) / sd(x), #intercept
sd(y) / sd(x),  #slope
lwd = 2)
points(mean(x), mean(y), cex = 2, pch = 19) #big point of intersection
X <- C(0.18, -1.54, 0.42, 0.95)
c <- c(0.18, -1.54, 0.42, 0.95)
x <- c(0.18, -1.54, 0.42, 0.95)
w <- (2, 1, 3, 1)
w <- c(2, 1, 3, 1)
sum(w*(x-0.3)^2)
sum(w*(x-1.077)^2)
sum(w*(x-0.1471)^2)
sum(w*(x-0.0025)^2)
(x-0.3)^2
w*(x-0.3)^2
sum(w*(x-0.3)^2)
sum(w*(x-0.0025)^2)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
corr(x,y)
cor(x,y)
cor(y,x)
lm(y ~ x)
library(datasets)
data(mtcars)
lm(mtcars$mpg ~ mtcars$weight)
lm(mtcars$mpg ~ mtcars$weight)
View(mtcars)
lm(mtcars$mpg ~ mtcars$weight)
lm(mtcars$mpg ~ mtcars$Wt)
lm(mtcars$mpg ~ mtcars$wt)
lm(mtcars$wt ~ mtcars$mpg)
x <- c(8.58, 10.46, 9.01, 9.64, 8.86)
mn <- mean(x)
stddev <- sd(x)
(8.58-mn)/stddev
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
lm(y ~ x)
mean(x)
swirl()
library(swirl)
swirl()
fit <- lm(child ~ parent, galton)
sum(fit$residual)^2/(928-2)
sqrt(sum(fit$residuals^2)/(n-2))
summary(fit)$sigma
sqrt(deviance(fit)/(n-2))
mu <- mean(galton$children)
mu <- mean(galton$child)
sTot <- sqrt(galton$child - mu)
sTot <- sqrt((galton$child - mu)^2)
sTot <- sum((galton$child - mu)^2)
sRes <- deviance(fit$residuals)
sRes <- deviance(residuals)
12
sRes <- deviance(fit)
sRes/sTot
1-sRes/sTot
summary(fit)$r
summary(fit)$r.squared
cor(galton$child,galton$parent)
cor(galton$child,galton$parent)^2
library(swirl)
swirl()
bye
quit()
library(UsingR)
data(galton)
library(dplyr); library(ggplot2)
freqData <- as.data.frame(table(galton$child, galton$parent))
View(freqData)
names(freqData) <- c("child", "parent", "freq")
View(freqData)
View(freqData)
freqData$child <- as.numeric(as.character(freqData$child))
freqData$parent <- as.numeric(as.character(freqData$parent))
g <- ggplot(filter(freqData, freq > 0), aes(x = parent, y = child))
g <- g  + scale_size(range = c(2, 20), guide = "none" )
g <- g + geom_point(colour="grey50", aes(size = freq+20, show_guide = FALSE))
g <- g + geom_point(aes(colour=freq, size = freq))
g <- g + scale_colour_gradient(low = "lightblue", high="white")
g
y <- galton$child
x <- galton$parent
beta1 <- cor(y, x) *  sd(y) / sd(x)
beta0 <- mean(y) - beta1 * mean(x)
rbind(c(beta0, beta1), coef(lm(y ~ x)))
beta1 <- cor(y, x) *  sd(x) / sd(y)
beta0 <- mean(x) - beta1 * mean(y)
rbind(c(beta0, beta1), coef(lm(x ~ y)))
yc <- y - mean(y)
xc <- x - mean(x)
beta1 <- sum(yc * xc) / sum(xc ^ 2)
c(beta1, coef(lm(y ~ x))[2])
## Revisiting Galton's data
### Normalizing variables results in the slope being the correlation
```{r, echo=TRUE}
yn <- (y - mean(y))/sd(y)
xn <- (x - mean(x))/sd(x)
c(cor(y, x), cor(yn, xn), coef(lm(yn ~ xn))[2])
```
yn <- (y - mean(y))/sd(y)
xn <- (x - mean(x))/sd(x)
c(cor(y, x), cor(yn, xn), coef(lm(yn ~ xn))[2])
g <- ggplot(filter(freqData, freq > 0), aes(x = parent, y = child))
g <- g  + scale_size(range = c(2, 20), guide = "none" )
g <- g + geom_point(colour="grey50", aes(size = freq+20, show_guide = FALSE))
g <- g + geom_point(aes(colour=freq, size = freq))
g <- g + scale_colour_gradient(low = "lightblue", high="white")
g <- g + geom_smooth(method="lm", formula=y~x)
g
g <- ggplot(filter(freqData, freq > 0), aes(x = parent, y = child))
g <- g  + scale_size(range = c(2, 20), guide = "none" )
g <- g + geom_point(colour="grey50", aes(size = freq+20, show_guide = FALSE))
g <- g + geom_point(aes(colour=freq, size = freq))
g <- g + scale_colour_gradient(low = "lightblue", high="white")
g <- g + geom_smooth(method="lm", formula=y~x)
g
```
library(knitr)
require(knitr)
summary(lm(mpg ~ . , data = mtcars))$coefficients
summary(lm(Fertility ~ Agriculture, data = swiss))$coefficients
summary(lm(Fertility ~ . , data = swiss))$coefficients
library(swirl)
swirl()
ones <- rep(1, nrow(galton))
lm(child ~ ones +parent -1,galton)
lm(child ~ parent,galton)
lm(child ~ 1,galton)
view(trees)
View(trees)
fit <- lm(Volume ~ Girth + Height + Constant -1, trees)
trees2 <- eliminate("Girth",trees)
head(trees2)
fit2 <- lm(Volume ~ Height + Constant -1, trees2)
lapply(list(fit, fit2),coef)
library(swirl)
swilr()
swirl()
lm(Fertility ~ , , data= swiss)
lm(Fertility ~ . , data= swiss)
library(swirl)
swirl()
library(caret); library(kernlab); data(spam)
inTrain <- createDataPartition(y=spam$type,
p=0.75, list=FALSE)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
hist(training$capitalAve,main="",xlab="ave. capital run length")
mean(training$capitalAve)
sd(training$capitalAve)
trainCapAve <- training$capitalAve
trainCapAveS <- (trainCapAve  - mean(trainCapAve))/sd(trainCapAve)
mean(trainCapAveS)
sd(trainCapAveS)
testCapAve <- testing$capitalAve
testCapAveS <- (testCapAve  - mean(trainCapAve))/sd(trainCapAve)
mean(testCapAveS)
sd(testCapAveS)
preObj <- preProcess(training[,-58],method=c("center","scale"))
trainCapAveS <- predict(preObj,training[,-58])$capitalAve
mean(trainCapAveS)
sd(trainCapAveS)
testCapAveS <- predict(preObj,testing[,-58])$capitalAve
mean(testCapAveS)
sd(testCapAveS)
set.seed(32343)
modelFit <- train(type ~.,data=training,
preProcess=c("center","scale"),method="glm")
modelFit
preObj <- preProcess(training[,-58],method=c("BoxCox"))
trainCapAveS <- predict(preObj,training[,-58])$capitalAve
par(mfrow=c(1,2)); hist(trainCapAveS); qqnorm(trainCapAveS)
set.seed(13343)
# Make some values NA
training$capAve <- training$capitalAve
selectNA <- rbinom(dim(training)[1],size=1,prob=0.05)==1
training$capAve[selectNA] <- NA
# Impute and standardize
preObj <- preProcess(training[,-58],method="knnImpute")
capAve <- predict(preObj,training[,-58])$capAve
# Standardize true values
capAveTruth <- training$capitalAve
capAveTruth <- (capAveTruth-mean(capAveTruth))/sd(capAveTruth)
quantile(capAve - capAveTruth)
quantile((capAve - capAveTruth)[selectNA])
quantile((capAve - capAveTruth)[!selectNA])
set.seed(13343)
# Make some values NA
training$capAve <- training$capitalAve
selectNA <- rbinom(dim(training)[1],size=1,prob=0.05)==1
training$capAve[selectNA] <- NA
# Impute and standardize
preObj <- preProcess(training[,-58],method="knnImpute")
capAve <- predict(preObj,training[,-58])$capAve
# Standardize true values
capAveTruth <- training$capitalAve
capAveTruth <- (capAveTruth-mean(capAveTruth))/sd(capAveTruth)
install.packages("RANN")
library(RANN)
set.seed(13343)
# Make some values NA
training$capAve <- training$capitalAve
selectNA <- rbinom(dim(training)[1],size=1,prob=0.05)==1
training$capAve[selectNA] <- NA
# Impute and standardize
preObj <- preProcess(training[,-58],method="knnImpute")
capAve <- predict(preObj,training[,-58])$capAve
# Standardize true values
capAveTruth <- training$capitalAve
capAveTruth <- (capAveTruth-mean(capAveTruth))/sd(capAveTruth)
quantile(capAve - capAveTruth)
quantile((capAve - capAveTruth)[selectNA])
quantile((capAve - capAveTruth)[!selectNA])
library(kernlab);data(spam)
spam$capitalAveSq <- spam$capitalAve^2
View(spam)
library(kernlab);data(spam)
spam$capitalAveSq <- spam$capitalAve^2
library(ISLR); library(caret); data(Wage);
inTrain <- createDataPartition(y=Wage$wage,
p=0.7, list=FALSE)
training <- Wage[inTrain,]; testing <- Wage[-inTrain,]
table(training$jobclass)
dummies <- dummyVars(wage ~ jobclass,data=training)
head(predict(dummies,newdata=training))
nsv <- nearZeroVar(training,saveMetrics=TRUE)
nsv
library(splines)
bsBasis <- bs(training$age,df=3)
bsBasis
lm1 <- lm(wage ~ bsBasis,data=training)
plot(training$age,training$wage,pch=19,cex=0.5)
points(training$age,predict(lm1,newdata=training),col="red",pch=19,cex=0.5)
predict(bsBasis,age=testing$age)
library(caret); library(kernlab); data(spam)
inTrain <- createDataPartition(y=spam$type,
p=0.75, list=FALSE)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
M <- abs(cor(training[,-58]))
diag(M) <- 0
which(M > 0.8,arr.ind=T)
M <- abs(cor(training[,-58]))
View(M)
diag(M) <- 0
which(M > 0.8,arr.ind=T)
View(M)
names(spam)[c(34,32)]
plot(spam[,34],spam[,32])
X <- 0.71*training$num415 + 0.71*training$num857
Y <- 0.71*training$num415 - 0.71*training$num857
plot(X,Y)
smallSpam <- spam[,c(34,32)]
prComp <- prcomp(smallSpam)
plot(prComp$x[,1],prComp$x[,2])
prComp$rotation
typeColor <- ((spam$type=="spam")*1 + 1)
prComp <- prcomp(log10(spam[,-58]+1))
plot(prComp$x[,1],prComp$x[,2],col=typeColor,xlab="PC1",ylab="PC2")
preProc <- preProcess(log10(spam[,-58]+1),method="pca",pcaComp=2)
spamPC <- predict(preProc,log10(spam[,-58]+1))
plot(spamPC[,1],spamPC[,2],col=typeColor)
preProc <- preProcess(log10(training[,-58]+1),method="pca",pcaComp=2)
trainPC <- predict(preProc,log10(training[,-58]+1))
modelFit <- train(training$type ~ .,method="glm",data=trainPC)
testPC <- predict(preProc,log10(testing[,-58]+1))
confusionMatrix(testing$type,predict(modelFit,testPC))
modelFit <- train(training$type ~ .,method="glm",preProcess="pca",data=training)
confusionMatrix(testing$type,predict(modelFit,testing))
library(caret);data(faithful); set.seed(333)
inTrain <- createDataPartition(y=faithful$waiting,
p=0.5, list=FALSE)
trainFaith <- faithful[inTrain,]; testFaith <- faithful[-inTrain,]
head(trainFaith)
plot(trainFaith$waiting,trainFaith$eruptions,pch=19,col="blue",xlab="Waiting",ylab="Duration")
lm1 <- lm(eruptions ~ waiting,data=trainFaith)
summary(lm1)
plot(trainFaith$waiting,trainFaith$eruptions,pch=19,col="blue",xlab="Waiting",ylab="Duration")
lines(trainFaith$waiting,lm1$fitted,lwd=3)
coef(lm1)[1] + coef(lm1)[2]*80
newdata <- data.frame(waiting=80)
predict(lm1,newdata)
par(mfrow=c(1,2))
plot(trainFaith$waiting,trainFaith$eruptions,pch=19,col="blue",xlab="Waiting",ylab="Duration")
lines(trainFaith$waiting,predict(lm1),lwd=3)
plot(testFaith$waiting,testFaith$eruptions,pch=19,col="blue",xlab="Waiting",ylab="Duration")
lines(testFaith$waiting,predict(lm1,newdata=testFaith),lwd=3)
# Calculate RMSE on training
sqrt(sum((lm1$fitted-trainFaith$eruptions)^2))
# Calculate RMSE on test
sqrt(sum((predict(lm1,newdata=testFaith)-testFaith$eruptions)^2))
pred1 <- predict(lm1,newdata=testFaith,interval="prediction")
ord <- order(testFaith$waiting)
plot(testFaith$waiting,testFaith$eruptions,pch=19,col="blue")
matlines(testFaith$waiting[ord],pred1[ord,],type="l",,col=c(1,2,2),lty = c(1,1,1), lwd=3)
modFit <- train(eruptions ~ waiting,data=trainFaith,method="lm")
summary(modFit$finalModel)
library(ISLR); library(ggplot2); library(caret);
data(Wage); Wage <- subset(Wage,select=-c(logwage))
summary(Wage)
inTrain <- createDataPartition(y=Wage$wage,
p=0.7, list=FALSE)
training <- Wage[inTrain,]; testing <- Wage[-inTrain,]
dim(training); dim(testing)
featurePlot(x=training[,c("age","education","jobclass")],
y = training$wage,
plot="pairs")
qplot(age,wage,data=training)
qplot(age,wage,colour=jobclass,data=training)
qplot(age,wage,colour=education,data=training)
modFit<- train(wage ~ age + jobclass + education,
method = "lm",data=training)
finMod <- modFit$finalModel
print(modFit)
plot(finMod,1,pch=19,cex=0.5,col="#00000010")
plot(finMod,1,pch=19,cex=0.5,col="#00000010")
qplot(finMod$fitted,finMod$residuals,colour=race,data=training)
plot(finMod$residuals,pch=19)
pred <- predict(modFit, testing)
qplot(wage,pred,colour=year,data=testing)
modFitAll<- train(wage ~ .,data=training,method="lm")
pred <- predict(modFitAll, testing)
qplot(wage,pred,data=testing)
library(ggplot2); library(caret);
# Download data.
dir_data_training <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
file_data_training <- "pml-training.csv"
download.file(url=dir_data_training, destfile=file_data_training, method="curl")
setwd("D:/cpinilla/personal/DataScientific/LearningMachine/Project")
install.packages("Rcurl")
install.packages("RCurl")
install.packages("RCurl")
install.packages("RCurl")
install.packages("RCurl")
install.packages("RCurl")
install.packages("RCurl")
install.packages("RCurl")
dir_data_training <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
file_data_training <- "pml-training.csv"
download.file(url=dir_data_training, destfile=file_data_training, method="curl")
library(ggplot2); library(caret);library(RCurl)
install.packages("RCurl")
